[project]
name = "voice-agent"
version = "0.1.0"
description = "Voice agent workspace"
readme = "README.md"
requires-python = ">=3.10"
dependencies = [
    # Web framework and server
    "fastapi",
    "uvicorn[standard]",
    "websockets",
    # HTTP clients
    "httpx",
    "sse-starlette",
    # Data validation
    "pydantic",
    "pyyaml",
    # Audio processing (core)
    "sounddevice",
    "numpy",
    "matplotlib",
    "pydub",
    "scipy", # For audio resampling
    # Hotkey management
    "pynput",
    # OBS
    "obs-websocket-py",
    # Bilibili blivedm dependencies
    "brotli~=1.1.0",
    "pure-protobuf~=3.1.2",
    "yarl~=1.9.3",
    # ML/AI frameworks (Core requirement)
    "torch==2.8.*",
    "torchaudio",
]

[project.optional-dependencies]
# STT Providers
stt-faster-whisper = [
    "faster-whisper>=1.2.1",
]
stt-funasr = [
    "funasr",
]
stt-all = [
    "faster-whisper>=1.2.1",
    "funasr",
]

# LLM Providers
llm-gemini = [
    "google-genai",
]
llm-ollama = [
    "ollama",
]
llm-llama-cpp = [
    "llama-cpp-python",
]
llm-all = [
    "google-genai",
    "ollama",
    "llama-cpp-python",
]

# TTS Providers
tts-edge = [
    "edge-tts==7.2.1",
]
tts-elevenlabs = [
    "elevenlabs",
]
tts-genie = [
    "genie-tts>=2.0.2",
]
tts-all = [
    "edge-tts==7.2.1",
    "elevenlabs",
    "genie-tts>=2.0.2",
]

# OCR (if using OCR features)
ocr = [
    "pyautogui",
    "paddleocr",
    "paddlepaddle",
    "pillow",
    "rapidfuzz",
]


# Convenience group: install all providers
all = [
    "faster-whisper>=1.2.1",
    "funasr",
    "google-genai",
    "ollama",
    "llama-cpp-python",
    "edge-tts==7.2.1",
    "elevenlabs",
    "genie-tts>=2.0.2",
    "pyautogui",
    "paddleocr",
    "paddlepaddle",
    "pillow",
    "rapidfuzz",
]


[tool.uv.sources]
# Install PyTorch with CUDA support on Linux/Windows (CUDA doesn't exist for Mac).
# This applies to all workspace members that depend on torch.
torch = [
    { index = "pytorch-cuda", marker = "sys_platform == 'linux' or sys_platform == 'win32'" },
]
torchaudio = [
    { index = "pytorch-cuda", marker = "sys_platform == 'linux' or sys_platform == 'win32'" },
]
torchvision = [
    { index = "pytorch-cuda", marker = "sys_platform == 'linux' or sys_platform == 'win32'" },
]

[[tool.uv.index]]
name = "pytorch-cuda"
# Use PyTorch built for NVIDIA Toolkit version 12.6.
# Available versions: https://pytorch.org/get-started/locally/
url = "https://download.pytorch.org/whl/cu126"
# Only use this index when explicitly requested by `tool.uv.sources`.
explicit = true

[dependency-groups]
dev = [
    "pytest>=9.0.2",
    "pytest-asyncio>=1.3.0",
    "mkdocs>=1.5.0",
    "mkdocs-material>=9.0.0",
]
